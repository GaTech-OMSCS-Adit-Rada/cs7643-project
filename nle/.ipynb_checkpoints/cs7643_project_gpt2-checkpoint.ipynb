{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr-qyFSktVrG"
   },
   "source": [
    "# CS7643: GPT2 From Scratch & Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vO2trnNoJ_sr"
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCDTFw8LZgcx"
   },
   "source": [
    "### [Optional] Set up Google Drive Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1745565286138,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "D0J9P8XZZKsH"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1745565286860,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "MfiVBmhzZMLY",
    "outputId": "edd9ce00-feb9-40a6-93ec-cc6ec8908f3d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1745565286907,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "JXUrVEoGZOSI",
    "outputId": "4143dd9a-33a8-47d3-dc93-e4e9854c55a2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: Fill in the Google Drive path where you uploaded assignment1\n",
    "# Example: If you create a Fall2023 folder and put all the files under A1 folder, then 'Fall2023/A1'\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'cs7643/project'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "print(os.listdir(GOOGLE_DRIVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745565286909,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "kHRgOKJ6ZbrX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GOOGLE_DRIVE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sys.path.append(GOOGLE_DRIVE_PATH)\n",
      "\u001b[31mNameError\u001b[39m: name 'GOOGLE_DRIVE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1745565286964,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "PK1Y7DZrjQeG",
    "outputId": "857073d6-524e-4502-f067-98bfce958f38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\python311.zip',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\Lib',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\DLLs',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project',\n",
       " '',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\Lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\Lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\Khanh Nguyen\\\\anaconda3\\\\envs\\\\cs7643-project\\\\Lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745565286964,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "zVXHDfnuZZZZ",
    "outputId": "95f14e83-cb5c-444d-dc1d-d972565dca59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0itX7X2zZn_s"
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7199,
     "status": "ok",
     "timestamp": 1745565294188,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "MNv9dhcltM9M",
    "outputId": "eae04c08-7391-4357-a97c-97d491d1ba76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khanh nguyen\\anaconda3\\envs\\cs7643-project\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1745565294232,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "r23i-TndKDkO",
    "outputId": "9cf64528-9026-4e36-870e-5f9406ae6208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3170,
     "status": "ok",
     "timestamp": 1745565297403,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "IeWaGyVlKGSq",
    "outputId": "6dd8069e-ee41-4dbf-d6e2-3ceb9f4275f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+cu121\n",
      "Using device = cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745565297404,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "j4HnzllKKHk-"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1745565297458,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "ta22rvfJpOxg"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1745565297969,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "Rv5-QQY6lAD1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1745565297985,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "vj2UrO4YlKHP"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjR2sCawk0TP"
   },
   "source": [
    "# 1. Implement a GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1745565298763,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "prULdEtOuuJr"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from model.gpt import GPTModel, text_to_token_ids, token_ids_to_text, generate, print_model_stats, TransformerBlock, classify_text_simple\n",
    "from model.load_model import load_weights\n",
    "from model.lora_gpt import LoRALayer, LinearWithLoRA, replace_linear_with_lora, replace_linear_with_lora_last_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8eGGcMtYB2F"
   },
   "source": [
    "## 1.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 12842,
     "status": "ok",
     "timestamp": 1745565312499,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "a-SVWsCM7Cs6"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "from transformers import GPT2Model\n",
    "\n",
    "# Available Models Names\n",
    "model_names = {\n",
    "    \"gpt2-small (124M)\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium (355M)\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"openai-community/gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"openai-community/gpt2-xl\"\n",
    "}\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "def get_raw_gpt(model_name):\n",
    "    if model_name not in model_configs:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "    base_config_copy = BASE_CONFIG.copy()\n",
    "    base_config_copy.update(model_configs[model_name])\n",
    "    return GPTModel(base_config_copy)\n",
    "\n",
    "def get_pretrained_gpt_model(model_name, verbose=True):\n",
    "    if model_name not in model_configs:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "    base_config_copy = BASE_CONFIG.copy()\n",
    "    base_config_copy.update(model_configs[model_name])\n",
    "    gpt_model = GPTModel(base_config_copy)\n",
    "\n",
    "    hf_pretrained_gpt = GPT2Model.from_pretrained(model_names[model_name], cache_dir=\"checkpoints\")\n",
    "    load_weights(gpt_model, hf_pretrained_gpt, base_config_copy)\n",
    "\n",
    "    if verbose:\n",
    "        print_model_stats(gpt_model, model_name)\n",
    "\n",
    "    return gpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1745565312772,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "YT2xtQfWlhKp"
   },
   "outputs": [],
   "source": [
    "def convert_to_lora_model(model: GPTModel, rank: int, alpha: int, last_n_trf_blocks=None) -> GPTModel:\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters after: {total_params:,}\")\n",
    "\n",
    "    if last_n_trf_blocks is not None:\n",
    "        replace_linear_with_lora_last_n(model, n=last_n_trf_blocks, rank=rank, alpha=alpha)\n",
    "    else:\n",
    "        replace_linear_with_lora(model, rank=rank, alpha=alpha)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable LoRA parameters: {total_params:,}\")\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745565312775,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "x263ce0wOmLW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1745565312821,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "HUm8OIRgnGJA"
   },
   "outputs": [],
   "source": [
    "from nle.train import calc_batch_loss, calc_loader_loss, evaluate_model, generate_and_print_sample, TrainingConfig, TrainingResults, train_model_simple, train_model\n",
    "from nle.train_plots import plot_losses, plot_perplexity, plot_and_save_learning_rate\n",
    "from nle.ClassificationDataset import ClassificationDataset, classification_collate_fn\n",
    "from nle.NLEWithGPT import NLEWithGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745565312822,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "Sw26kCwgJp9g"
   },
   "outputs": [],
   "source": [
    "def print_model_losses(model, train_loader, val_loader, device):\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loader_loss(train_loader, model, device, num_batches=5)\n",
    "        val_loss = calc_loader_loss(val_loader, model, device, num_batches=5)\n",
    "\n",
    "    print(\"Training loss:\", train_loss)\n",
    "    print(\"Validation loss:\", val_loss)\n",
    "    print(\"Training perplexity:\", torch.exp(torch.tensor(train_loss)).item())\n",
    "    print(\"Validation perplexity:\", torch.exp(torch.tensor(val_loss)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745565312824,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "YAAFTViCZ3Ti"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def download_and_load_json_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745565312827,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "efiB2bnde7LX"
   },
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is a natural language entailment data classification. \"\n",
    "        f\"Write a response that appropriately determines the medical relationship between a premise (sentence 1) and a hypothesis (sentence 2)\"\n",
    "        f\"\\n\\n### Premise:\\n{entry['premise']}\"\n",
    "        f\"\\n\\n### hypothesis:\\n{entry['hypothesis']}\"\n",
    "    )\n",
    "\n",
    "    return instruction_text\n",
    "\n",
    "def format_response(entry):\n",
    "    return entry['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1745565312829,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "Uip0rvfyng-6"
   },
   "outputs": [],
   "source": [
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1745565312869,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "cLjYSSPZI7Yi"
   },
   "outputs": [],
   "source": [
    "def generate_model_response(model, test_data, file_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "            instruction_text = format_input(entry)\n",
    "            token_ids = generate(\n",
    "                model=model.to(device),\n",
    "                token_ids=text_to_token_ids(instruction_text, tokenizer).to(device),\n",
    "                max_new_tokens=512,\n",
    "                context_size=BASE_CONFIG[\"context_length\"],\n",
    "                eos_id=50256,\n",
    "            )\n",
    "            generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "            response_text = generated_text[len(instruction_text):].replace(\"### Response:\", \"\").strip()\n",
    "            entry[\"generated_text\"] = response_text\n",
    "\n",
    "    # Save the data\n",
    "    if file_path:\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(test_data, f, indent=4)\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1745565312911,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "KilDuOmYKBmf"
   },
   "outputs": [],
   "source": [
    "def print_model_losses(model, train_loader, val_loader, device):\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loader_loss(train_loader, model, device, num_batches=5)\n",
    "        val_loss = calc_loader_loss(val_loader, model, device, num_batches=5)\n",
    "\n",
    "    print(\"Training loss:\", train_loss)\n",
    "    print(\"Validation loss:\", val_loss)\n",
    "    print(\"Training perplexity:\", torch.exp(torch.tensor(train_loss)).item())\n",
    "    print(\"Validation perplexity:\", torch.exp(torch.tensor(val_loss)).item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1745565312952,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "h-54tNnQacMN"
   },
   "outputs": [],
   "source": [
    "def filter_data_by_len(data_type=\"train\", target_size=12000, filepath=None):\n",
    "    splits = {'test': 'plain_text/test-00000-of-00001.parquet', 'validation': 'plain_text/validation-00000-of-00001.parquet', 'train': 'plain_text/train-00000-of-00001.parquet'}\n",
    "    data = pd.read_parquet(\"hf://datasets/stanfordnlp/snli/\" + splits[data_type])\n",
    "    # splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "    # path = \"hf://datasets/presencesw/all_nli_med_v1/\" + splits[data_type]\n",
    "    # data = pd.read_parquet(\"hf://datasets/presencesw/all_nli_med_v1/\" + splits[data_type])\n",
    "    # print(data)\n",
    "    entailment_subset = data[data[\"label\"] == 0].sample(int(target_size/3), random_state=123)\n",
    "    neutral_subset = data[data[\"label\"] == 1].sample(int(target_size/3), random_state=123)\n",
    "    contradict_subset = data[data[\"label\"] == 2].sample(int(target_size/3), random_state=123)\n",
    "    \n",
    "    # entailment_subset = data[data[\"gold_label\"] == \"entailment\"].sample(int(target_size/3), random_state=123)\n",
    "    # contradict_subset = data[data[\"gold_label\"] == \"contradiction\"].sample(int(target_size/3), random_state=123)\n",
    "    # neutral_subset = data[data[\"gold_label\"] == \"neutral\"].sample(int(target_size/3), random_state=123)\n",
    "    \n",
    "    \n",
    "    # Combine both subsets\n",
    "    sample_df = pd.concat([entailment_subset, contradict_subset,neutral_subset])\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    sample_df = sample_df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    if filepath:\n",
    "        sample_df.to_json(filepath, orient='records', indent=4)  # Save as JSON\n",
    "\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPdJyLA6hL4Z"
   },
   "source": [
    "## 5.2 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fe9arV26e4C4"
   },
   "source": [
    "## 5.1 Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3522,
     "status": "ok",
     "timestamp": 1745565316473,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "UBEEFb7gy_Rq",
    "outputId": "fe96c820-00cb-471c-824d-2df901310d0e"
   },
   "outputs": [],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "train_data = filter_data_by_len(data_type=\"train\", target_size=2000)\n",
    "val_data = filter_data_by_len(data_type=\"validation\", target_size=100)\n",
    "test_data = filter_data_by_len(data_type=\"test\", target_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1745565316533,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "JAfrYT3Ve7Oe",
    "outputId": "575c1396-2565-46a4-ae5b-d43717e54c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " premise       The motorcycle is a Honda.\n",
      "hypothesis     The motorcycle is a Ford.\n",
      "label                                  2\n",
      "Name: 50, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", train_data.iloc[50])\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1745565316922,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "059JD76VqsRE",
    "outputId": "679aedc7-4c1c-474c-95b5-4af52d6cb00d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the first 30 entries to nle_sample_generation_data_30.json\n"
     ]
    }
   ],
   "source": [
    "def save_first_n_entries(data, n, filename):\n",
    "    \"\"\"Saves the first n entries of the data to a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data.head(n).to_dict(orient='records'), f, indent=4) # Use indent for pretty printing\n",
    "        print(f\"Successfully saved the first {n} entries to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "save_first_n_entries(\n",
    "    train_data, 30,\n",
    "    \"nle_sample_generation_data_30.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745565316931,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "D6vtd7YAifRx",
    "outputId": "ab0856e8-5459-4f95-bd09-c2559f46cec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a natural language entailment data classification. Write a response that appropriately determines the medical relationship between a premise (sentence 1) and a hypothesis (sentence 2)\n",
      "\n",
      "### Premise:\n",
      "The motorcycle is a Honda.\n",
      "\n",
      "### hypothesis:\n",
      "The motorcycle is a Ford.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.int64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(format_input(train_data.iloc[\u001b[32m50\u001b[39m]))\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mlabel: \u001b[39m\u001b[33m\"\u001b[39m + format_response(train_data.iloc[\u001b[32m50\u001b[39m]))\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"numpy.int64\") to str"
     ]
    }
   ],
   "source": [
    "print(format_input(train_data.iloc[50]))\n",
    "print(\"label: \" + format_response(train_data.iloc[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1745565316933,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "HRSK5iGle7Ig"
   },
   "outputs": [],
   "source": [
    "# train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "# test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "# val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "# train_data = data[:train_portion]\n",
    "# test_data = data[train_portion:train_portion + test_portion]\n",
    "# val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1745565316942,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "eN-P8iqoe7FV",
    "outputId": "a02f2061-cb4a-451d-a3f0-5c223455947c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 1998\n",
      "Validation set length: 99\n",
      "Test set length: 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1745565316970,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "ZTlWteRqacMO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plYJLPT5mGTs"
   },
   "source": [
    "## 5.3 Creating data loaders for classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1745565317511,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "f94-uFkbgZI_",
    "outputId": "1baa878f-65f6-4999-e24b-6fd58804a058"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m batch_size = \u001b[32m2\u001b[39m\n\u001b[32m     15\u001b[39m torch.manual_seed(\u001b[32m123\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m train_dataset = ClassificationDataset(train_data, tokenizer,max_length=\u001b[32m1024\u001b[39m)\n\u001b[32m     18\u001b[39m train_loader = DataLoader(\n\u001b[32m     19\u001b[39m     train_dataset,\n\u001b[32m     20\u001b[39m     batch_size=batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     num_workers=num_workers\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m val_dataset = ClassificationDataset(val_data, tokenizer,max_length=\u001b[32m1024\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:18\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, data, tokenizer, max_length, pad_token_id)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 1"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "customized_collate_fn = partial(\n",
    "    classification_collate_fn,\n",
    "    tokenizer=tokenizer,\n",
    "    allowed_max_length=1024,\n",
    "    pad_token_id=50256,\n",
    "    device=device\n",
    "    # device=\"cpu\"\n",
    ")\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = ClassificationDataset(train_data, tokenizer,max_length=1024)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    # collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = ClassificationDataset(val_data, tokenizer,max_length=1024)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    # collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = ClassificationDataset(test_data, tokenizer,max_length=1024)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    # collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1745565317883,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "S7x61mfFe7CN",
    "outputId": "7422230a-3138-4fe5-c1a7-698ba5b2c189"
   },
   "outputs": [],
   "source": [
    "print(\"Train loader:\")\n",
    "i = 0\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    if i == 3: break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYqvauqh0nR5"
   },
   "source": [
    "## 5.4 Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7569,
     "status": "ok",
     "timestamp": 1745565325452,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "aX2GQyq6cDG7",
    "outputId": "6006a3e3-6c21-403d-bdc8-060ceeeb33bd"
   },
   "outputs": [],
   "source": [
    "# CHOOSE_MODEL = \"gpt2-large (774M)\"\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "gpt_m = get_pretrained_gpt_model(CHOOSE_MODEL)\n",
    "# nleModel = NLEWithGPT(gpt_m)\n",
    "nleModel = NLEWithGPT(gpt_m).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1745565325536,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "rplwttIG3DjU",
    "outputId": "07a331ce-68dd-4179-ebfe-96e5952bc95a"
   },
   "outputs": [],
   "source": [
    "input_text = format_input(val_data.iloc[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1745565325787,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "es3az17y2jyw",
    "outputId": "ccee6a63-3c67-4259-ce57-494080cd836d"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# token_ids = text_to_token_ids(input_text, tokenizer)\n",
    "token_ids = text_to_token_ids(input_text, tokenizer).to(device)\n",
    "classified_label = classify_text_simple(nleModel, token_ids)\n",
    "print(\"Output label: \", classified_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vX9LBfQ53sG5"
   },
   "source": [
    "## 5.5 Finetuning the LLM on NLE data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PyBCd2x5zc9"
   },
   "source": [
    "Initial Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5064,
     "status": "ok",
     "timestamp": 1745565330850,
     "user": {
      "displayName": "Quinn Nguyen",
      "userId": "08227019119404684362"
     },
     "user_tz": 420
    },
    "id": "oXSXMMYW3jmv",
    "outputId": "15779fd0-c46a-4933-e469-be3a355b27e5"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loader_loss(train_loader, nleModel, device, num_batches=5)\n",
    "    val_loss = calc_loader_loss(val_loader, nleModel, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDn4kE5_3jjm",
    "outputId": "a562f928-2f40-4f65-dc3b-9af257de18df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(nleModel.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    model=nleModel,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "training_results = train_model_simple(training_config)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-jQHEZA6eJb"
   },
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(\n",
    "    0, num_epochs, len(ift_mini_alpaca_training_results.train_losses))\n",
    "\n",
    "plot_losses(ift_mini_alpaca_training_config,ift_mini_alpaca_training_results)\n",
    "            # ift_mini_alpaca_training_results.track_tokens_seen,\n",
    "            # ift_mini_alpaca_training_results.train_losses,\n",
    "            # ift_mini_alpaca_training_results.val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv8QZoDL9bh-"
   },
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=gpt_m.to(device),\n",
    "    token_ids=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(\"Output text:\\n\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XCDTFw8LZgcx",
    "DPdJyLA6hL4Z"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
